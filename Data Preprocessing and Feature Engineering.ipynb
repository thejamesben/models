{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f26fee2",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Feature Engineering\n",
    "\n",
    "#### Introduction\n",
    "Data preprocessing and feature engineering are crucial steps in preparing raw data for modeling. These steps involve cleaning the data, handling missing values, transforming the data, normalizing the features, and engineering new features. The goal is to create a high-quality dataset that can be used to build accurate and robust predictive models.\n",
    "\n",
    "#### Loading the Data\n",
    "The dataset is loaded from a CSV file into a pandas DataFrame. This step reads the raw data into memory for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f5c1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('ucs_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f427e6",
   "metadata": {},
   "source": [
    "#### Data Cleaning\n",
    "Data cleaning involves removing duplicates, filtering out invalid entries, and ensuring that the data is consistent and accurate. In this step, duplicates are removed, cancelled transactions are filtered out, and only positive quantities are retained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cef16448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "data.drop_duplicates(inplace=True)\n",
    "data = data[~data['Invoice'].str.contains('C', na=False)]\n",
    "data = data[data['Quantity'] > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d17e3",
   "metadata": {},
   "source": [
    "#### Handling Missing Values\n",
    "Missing values can significantly impact the performance of machine learning models. In this step, records with missing `Customer ID` and `Description` values are removed to ensure data completeness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ab08ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values\n",
    "data.dropna(subset=['Customer ID', 'Description'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7df83",
   "metadata": {},
   "source": [
    "#### Data Transformation\n",
    "Data transformation involves converting data into a suitable format for analysis. Here, the `InvoiceDate` is converted to a datetime format, and a new feature `TotalPrice` is created by multiplying `Quantity` and `Price`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "559b6056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation\n",
    "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
    "data['TotalPrice'] = data['Quantity'] * data['Price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f79dc2",
   "metadata": {},
   "source": [
    "#### Data Normalization\n",
    "Normalization scales the numerical features to a standard range, which helps in improving the performance and training stability of machine learning models. The `Quantity` and `Price` features are scaled to a range between 0 and 1 using MinMaxScaler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "332a71a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "data[['Quantity', 'Price']] = scaler.fit_transform(data[['Quantity', 'Price']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6935e39",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "Feature engineering involves creating new features from the existing data to enhance the predictive power of the model. In this step, new features such as `Year`, `Month`, and `DayOfWeek` are extracted from the `InvoiceDate`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c763d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "data['Year'] = data['InvoiceDate'].dt.year\n",
    "data['Month'] = data['InvoiceDate'].dt.month\n",
    "data['DayOfWeek'] = data['InvoiceDate'].dt.dayofweek\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d4d7f",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding\n",
    "One-hot encoding is applied to categorical features to convert them into a numerical format that can be used by machine learning algorithms. The `Country` feature is one-hot encoded, and the resulting encoded features are concatenated with the original dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49bc2cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dacawave/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "country_encoded = encoder.fit_transform(data[['Country']])\n",
    "country_df = pd.DataFrame(country_encoded, columns=encoder.get_feature_names_out(['Country']))\n",
    "data = pd.concat([data.reset_index(drop=True), country_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f766e",
   "metadata": {},
   "source": [
    "#### Saving the Preprocessed Data\n",
    "The final preprocessed dataset is saved to a CSV file, `preprocessed_data.csv` for future use. This step ensures that the cleaned and transformed data is stored and can be easily accessed for model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c16b9107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessing and Feature Engineering Completed\n"
     ]
    }
   ],
   "source": [
    "data.to_csv('preprocessed_data.csv', index=False)\n",
    "print('Data Preprocessing and Feature Engineering Completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329508d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
